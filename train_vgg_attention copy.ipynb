{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import sample\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Must be set before importing TF to supress messages\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import numpy as np\n",
    "from utils.loader import DataLoader\n",
    "from utils.tools import test_model, insert_attention_layer_in_keras\n",
    "from utils.data_sampler import CustomDataGenerator, CustomIterator\n",
    "from utils.configs import config\n",
    "from typing import List\n",
    "import pymf\n",
    "\n",
    "def load_VGG_model(img_height: int, img_width: int, lr: int, loss: tf.keras.losses.Loss, metrics: List[str], trainable: True) -> tf.keras.Model:\n",
    "    \"\"\" Loads VGG-16 model.\n",
    "\n",
    "    Args:\n",
    "        img_height (int): Image height.\n",
    "        img_width (int): Image width.\n",
    "        lr (int): Learning rate.\n",
    "        loss (tf.keras.losses.Loss): Model loss.\n",
    "        metrics (List[str]): Training metrics.\n",
    "        trainable (True): Set if model weights should be kept frozen or not.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: TensorFlow VGG-16 model.\n",
    "    \"\"\"\n",
    "    model = tf.keras.applications.vgg16.VGG16(input_shape=(img_height, img_width, 3))\n",
    "    model.trainable = trainable\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr, epsilon=0.1),\n",
    "                loss=loss,\n",
    "                metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model: tf.keras.Model, train_set: CustomIterator, val_set: CustomIterator, epochs: int, batch_size: int, callbacks=None):\n",
    "    \"\"\" Train the model. \n",
    "\n",
    "    Args:\n",
    "        train_set (CustomIterator): Training data.\n",
    "        val_set (CustomIterator): Validation data.\n",
    "        epochs (int): Number of epochs to train for.\n",
    "        callbacks (_type_, optional): Callbacks for loggers. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        history: Model training history information.\n",
    "    \"\"\"\n",
    "    history = model.fit(train_set, validation_data=val_set, validation_freq=1, epochs=epochs, steps_per_epoch=train_set.n//batch_size, validation_steps=val_set.n//batch_size if val_set is not None else None, verbose=1, callbacks=callbacks)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensure sampling correct during training\n",
    "- Use same training params as Freddie paper\n",
    "- Early stopping once validation loss increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configs\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "lr = 3e-4\n",
    "log_path = os.path.join(config['logs_path'], 'vgg_baseline_attention_model_42.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train set...\n",
      "Found 1153101 images belonging to 1000 classes.\n",
      "Loading validation set...\n",
      "Found 128066 images belonging to 1000 classes.\n",
      "Loading test set...\n",
      "Found 48238 images belonging to 1000 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set augmentation and pre-processing\n",
    "train_datagen = CustomDataGenerator(\n",
    "                horizontal_flip=True,\n",
    "                validation_split=0.1,\n",
    "                preprocessing_function=tf.keras.applications.vgg16.preprocess_input, dtype=tf.float32)\n",
    "test_datagen = CustomDataGenerator(\n",
    "                preprocessing_function=tf.keras.applications.vgg16.preprocess_input, dtype=tf.float32)\n",
    "\n",
    "# Load ImageNet dataset with the VGG augmentation\n",
    "loader = DataLoader(batch_size, (img_height, img_width))\n",
    "train_set = loader.load_train_set(aug_train=train_datagen, class_mode='categorical', shuffle=True)\n",
    "val_set = loader.load_val_set(aug_val=train_datagen, class_mode='categorical', shuffle=True)\n",
    "test_set = loader.load_test_set(aug_test=test_datagen, set_batch_size=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG-16 model\n",
    "model = tf.keras.models.load_model('models/vgg_trained')\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get layer kernel\n",
    "kernel = model.get_layer('block4_conv3').kernel\n",
    "flat_kernel = tf.reshape(kernel, [-1, kernel.shape[-1]]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get projection matrix via SNMF\n",
    "n_comp = 42\n",
    "\n",
    "nmf = pymf.SNMF(flat_kernel, num_bases=n_comp)\n",
    "nmf.factorize(niter=400)\n",
    "p_mat = nmf.H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert attention layer\n",
    "model = insert_attention_layer_in_keras(p_mat, model, ['block5_conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable subsampling equal to standard size\n",
    "train_set.set_subsampling(size=1170*2, force_class_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 643s 38s/step - loss: 0.7089 - accuracy: 0.8103 - val_loss: 0.7602 - val_accuracy: 0.7899\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 646s 38s/step - loss: 0.6892 - accuracy: 0.8062 - val_loss: 0.7601 - val_accuracy: 0.7897\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 650s 38s/step - loss: 0.6343 - accuracy: 0.8250 - val_loss: 0.7613 - val_accuracy: 0.7902\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 651s 38s/step - loss: 0.7530 - accuracy: 0.7925 - val_loss: 0.7600 - val_accuracy: 0.7899\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 658s 39s/step - loss: 0.6622 - accuracy: 0.8073 - val_loss: 0.7602 - val_accuracy: 0.7905\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 642s 38s/step - loss: 0.6863 - accuracy: 0.8032 - val_loss: 0.7589 - val_accuracy: 0.7904\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 643s 38s/step - loss: 0.6728 - accuracy: 0.8074 - val_loss: 0.7602 - val_accuracy: 0.7903\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 642s 38s/step - loss: 0.6188 - accuracy: 0.8179 - val_loss: 0.7607 - val_accuracy: 0.7892\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 647s 38s/step - loss: 0.6345 - accuracy: 0.8218 - val_loss: 0.7608 - val_accuracy: 0.7904\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 644s 38s/step - loss: 0.7452 - accuracy: 0.7900 - val_loss: 0.7602 - val_accuracy: 0.7902\n"
     ]
    }
   ],
   "source": [
    "# Train and use CSV logger to store logs\n",
    "if not os.path.exists(log_path):\n",
    "    with open(log_path, \"w\") as my_empty_csv: pass\n",
    "\n",
    "csv_logger = CSVLogger(log_path, separator=',', append=False)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "train_history = train_model(model=model, train_set=train_set, val_set=val_set, epochs=epochs, batch_size=batch_size, callbacks=[csv_logger, early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took 18, 10, 11, 10 for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/baselines/baseline256')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f19a825d400>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('models/baselines/baseline256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting on test-set...\n",
      "48238/48238 [==============================] - 234s 5ms/step\n",
      "Computing accuracy...\n",
      "\n",
      "-----------------------------------------\n",
      "Model Accuracy on test-set: 0.6986608068327874\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('splash2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "febfae6c9c9e1571e6e03dfd739a8f6fb010085a8ae682416bd437b2f090be32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
