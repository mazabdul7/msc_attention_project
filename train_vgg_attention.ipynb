{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import sample\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Must be set before importing TF to supress messages\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import numpy as np\n",
    "from utils.loader import DataLoader\n",
    "from utils.tools import test_model, insert_attention_layer_in_keras\n",
    "from utils.data_sampler import CustomDataGenerator, CustomIterator\n",
    "from utils.configs import config\n",
    "from typing import List\n",
    "import pymf\n",
    "\n",
    "def load_VGG_model(img_height: int, img_width: int, lr: int, loss: tf.keras.losses.Loss, metrics: List[str], trainable: True) -> tf.keras.Model:\n",
    "    \"\"\" Loads VGG-16 model.\n",
    "\n",
    "    Args:\n",
    "        img_height (int): Image height.\n",
    "        img_width (int): Image width.\n",
    "        lr (int): Learning rate.\n",
    "        loss (tf.keras.losses.Loss): Model loss.\n",
    "        metrics (List[str]): Training metrics.\n",
    "        trainable (True): Set if model weights should be kept frozen or not.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: TensorFlow VGG-16 model.\n",
    "    \"\"\"\n",
    "    model = tf.keras.applications.vgg16.VGG16(input_shape=(img_height, img_width, 3))\n",
    "    model.trainable = trainable\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr, epsilon=0.1),\n",
    "                loss=loss,\n",
    "                metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model: tf.keras.Model, train_set: CustomIterator, val_set: CustomIterator, epochs: int, batch_size: int, callbacks=None):\n",
    "    \"\"\" Train the model. \n",
    "\n",
    "    Args:\n",
    "        train_set (CustomIterator): Training data.\n",
    "        val_set (CustomIterator): Validation data.\n",
    "        epochs (int): Number of epochs to train for.\n",
    "        callbacks (_type_, optional): Callbacks for loggers. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        history: Model training history information.\n",
    "    \"\"\"\n",
    "    history = model.fit(train_set, validation_data=val_set, validation_freq=1, epochs=epochs, steps_per_epoch=train_set.n//batch_size, validation_steps=val_set.n//batch_size if val_set is not None else None, verbose=1, callbacks=callbacks)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensure sampling correct during training\n",
    "- Use same training params as Freddie paper\n",
    "- Early stopping once validation loss increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configs\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "lr = 3e-4\n",
    "log_path = os.path.join(config['logs_path'], 'vgg_baseline_attention_model_256.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set augmentation and pre-processing\n",
    "train_datagen = CustomDataGenerator(\n",
    "                horizontal_flip=True,\n",
    "                validation_split=0.1,\n",
    "                preprocessing_function=tf.keras.applications.vgg16.preprocess_input, dtype=tf.float32)\n",
    "test_datagen = CustomDataGenerator(\n",
    "                preprocessing_function=tf.keras.applications.vgg16.preprocess_input, dtype=tf.float32)\n",
    "\n",
    "# Load ImageNet dataset with the VGG augmentation\n",
    "loader = DataLoader(batch_size, (img_height, img_width))\n",
    "train_set = loader.load_train_set(aug_train=train_datagen, class_mode='categorical', shuffle=True)\n",
    "val_set = loader.load_val_set(aug_val=train_datagen, class_mode='categorical', shuffle=True)\n",
    "test_set = loader.load_test_set(aug_test=test_datagen, set_batch_size=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG-16 model\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.load_model('models/vgg_trained')\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get layer kernel\n",
    "kernel = model.get_layer('block4_conv3').kernel\n",
    "flat_kernel = tf.reshape(kernel, [-1, kernel.shape[-1]]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get projection matrix via SNMF\n",
    "n_comp = 256\n",
    "\n",
    "nmf = pymf.SNMF(flat_kernel, num_bases=n_comp)\n",
    "nmf.factorize(niter=400)\n",
    "p_mat = nmf.H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert attention layer\n",
    "model = insert_attention_layer_in_keras(p_mat, model, ['block5_conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable subsampling equal to standard size\n",
    "train_set.set_subsampling(size=1170*2, force_class_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 322s 19s/step - loss: 0.6138 - accuracy: 0.8236 - val_loss: 0.7642 - val_accuracy: 0.7892\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 322s 19s/step - loss: 0.6785 - accuracy: 0.8141 - val_loss: 0.7639 - val_accuracy: 0.7900\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 324s 19s/step - loss: 0.7259 - accuracy: 0.8039 - val_loss: 0.7605 - val_accuracy: 0.7904\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 319s 19s/step - loss: 0.7055 - accuracy: 0.8029 - val_loss: 0.7634 - val_accuracy: 0.7908\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 322s 19s/step - loss: 0.6921 - accuracy: 0.7926 - val_loss: 0.7591 - val_accuracy: 0.7918\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 319s 19s/step - loss: 0.7015 - accuracy: 0.7900 - val_loss: 0.7649 - val_accuracy: 0.7907\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 320s 19s/step - loss: 0.6689 - accuracy: 0.8141 - val_loss: 0.7626 - val_accuracy: 0.7896\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 318s 19s/step - loss: 0.6922 - accuracy: 0.8066 - val_loss: 0.7525 - val_accuracy: 0.7938\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 320s 19s/step - loss: 0.6491 - accuracy: 0.8154 - val_loss: 0.7575 - val_accuracy: 0.7920\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 317s 19s/step - loss: 0.8126 - accuracy: 0.7844 - val_loss: 0.7625 - val_accuracy: 0.7903\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 321s 19s/step - loss: 0.6608 - accuracy: 0.8262 - val_loss: 0.7646 - val_accuracy: 0.7900\n"
     ]
    }
   ],
   "source": [
    "# Train and use CSV logger to store logs\n",
    "if not os.path.exists(log_path):\n",
    "    with open(log_path, \"w\") as my_empty_csv: pass\n",
    "\n",
    "csv_logger = CSVLogger(log_path, separator=',', append=False)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "train_history = train_model(model=model, train_set=train_set, val_set=val_set, epochs=epochs, batch_size=batch_size, callbacks=[csv_logger, early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took 16, 16, 14, 18 for convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9, 10, 10, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/baselines2/baseline90')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f17484d16d0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f'models/baselines/baseline256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting on test-set...\n",
      "48238/48238 [==============================] - 239s 5ms/step\n",
      "Computing accuracy...\n",
      "\n",
      "-----------------------------------------\n",
      "Model Accuracy on test-set: 0.6979766988681123\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('splash2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "febfae6c9c9e1571e6e03dfd739a8f6fb010085a8ae682416bd437b2f090be32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
