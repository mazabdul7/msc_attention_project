{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import sample\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Must be set before importing TF to supress messages\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import numpy as np\n",
    "from utils.loader import DataLoader\n",
    "from utils.tools import test_model, insert_attention_layer_in_keras\n",
    "from utils.data_sampler import CustomDataGenerator, CustomIterator\n",
    "from utils.configs import config\n",
    "from typing import List\n",
    "import pymf\n",
    "\n",
    "def load_VGG_model(img_height: int, img_width: int, lr: int, loss: tf.keras.losses.Loss, metrics: List[str], trainable: True) -> tf.keras.Model:\n",
    "    \"\"\" Loads VGG-16 model.\n",
    "\n",
    "    Args:\n",
    "        img_height (int): Image height.\n",
    "        img_width (int): Image width.\n",
    "        lr (int): Learning rate.\n",
    "        loss (tf.keras.losses.Loss): Model loss.\n",
    "        metrics (List[str]): Training metrics.\n",
    "        trainable (True): Set if model weights should be kept frozen or not.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: TensorFlow VGG-16 model.\n",
    "    \"\"\"\n",
    "    model = tf.keras.applications.vgg16.VGG16(input_shape=(img_height, img_width, 3))\n",
    "    model.trainable = trainable\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr, epsilon=0.1),\n",
    "                loss=loss,\n",
    "                metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model: tf.keras.Model, train_set: CustomIterator, val_set: CustomIterator, epochs: int, batch_size: int, callbacks=None):\n",
    "    \"\"\" Train the model. \n",
    "\n",
    "    Args:\n",
    "        train_set (CustomIterator): Training data.\n",
    "        val_set (CustomIterator): Validation data.\n",
    "        epochs (int): Number of epochs to train for.\n",
    "        callbacks (_type_, optional): Callbacks for loggers. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        history: Model training history information.\n",
    "    \"\"\"\n",
    "    history = model.fit(train_set, validation_data=val_set, validation_freq=1, epochs=epochs, steps_per_epoch=train_set.n//batch_size, validation_steps=val_set.n//batch_size if val_set is not None else None, verbose=1, callbacks=callbacks)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensure sampling correct during training\n",
    "- Use same training params as Freddie paper\n",
    "- Early stopping once validation loss increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configs\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "lr = 3e-4\n",
    "log_path = os.path.join(config['logs_path'], 'vgg_baseline_attention_model_256.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set augmentation and pre-processing\n",
    "train_datagen = CustomDataGenerator(\n",
    "                horizontal_flip=True,\n",
    "                validation_split=0.1,\n",
    "                preprocessing_function=tf.keras.applications.vgg16.preprocess_input, dtype=tf.float32)\n",
    "test_datagen = CustomDataGenerator(\n",
    "                preprocessing_function=tf.keras.applications.vgg16.preprocess_input, dtype=tf.float32)\n",
    "\n",
    "# Load ImageNet dataset with the VGG augmentation\n",
    "loader = DataLoader(batch_size, (img_height, img_width))\n",
    "train_set = loader.load_train_set(aug_train=train_datagen, class_mode='categorical', shuffle=True)\n",
    "val_set = loader.load_val_set(aug_val=train_datagen, class_mode='categorical', shuffle=True)\n",
    "test_set = loader.load_test_set(aug_test=test_datagen, set_batch_size=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG-16 model\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.load_model('models/vgg_trained')\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get layer kernel\n",
    "kernel = model.get_layer('block4_conv3').kernel\n",
    "flat_kernel = tf.reshape(kernel, [-1, kernel.shape[-1]]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get projection matrix via SNMF\n",
    "n_comp = 256\n",
    "\n",
    "nmf = pymf.SNMF(flat_kernel, num_bases=n_comp)\n",
    "nmf.factorize(niter=400)\n",
    "p_mat = nmf.H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert attention layer\n",
    "model = insert_attention_layer_in_keras(p_mat, model, ['block5_conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{17: <tf.Variable 'attention_block5_conv1/seeds:0' shape=(1, 17) dtype=float32, numpy=\n",
       " array([[ 1.09064765e-02,  1.18806930e-02,  4.10769353e-05,\n",
       "          1.94557942e-03,  8.69130017e-04,  1.36443144e-02,\n",
       "          1.22951102e-02,  8.34141206e-03,  6.67547924e-04,\n",
       "          2.26908904e-02,  4.72601317e-03,  5.30491397e-03,\n",
       "          1.11149158e-02,  4.40227846e-03,  4.36795782e-03,\n",
       "         -0.00000000e+00,  8.11986066e-03]], dtype=float32)>,\n",
       " 42: <tf.Variable 'attention_block5_conv1/seeds:0' shape=(1, 42) dtype=float32, numpy=\n",
       " array([[4.3946380e-05, 7.9736157e-05, 2.7587002e-05, 3.5155084e-05,\n",
       "         3.3212738e-05, 4.1611118e-05, 6.6966997e-05, 6.9196307e-05,\n",
       "         5.3129468e-05, 5.3348784e-05, 8.4001978e-05, 4.0101255e-05,\n",
       "         5.3345429e-05, 4.4363493e-05, 6.0484261e-05, 3.4808745e-05,\n",
       "         6.9153110e-05, 4.8986360e-05, 4.9627008e-05, 1.9349829e-05,\n",
       "         3.9913215e-05, 8.6844957e-05, 4.1048217e-05, 9.7548887e-05,\n",
       "         1.4989413e-05, 5.0479197e-05, 4.9211681e-05, 6.3506603e-05,\n",
       "         6.0652717e-05, 5.1129769e-05, 2.5190033e-05, 1.1846649e-04,\n",
       "         3.5077326e-05, 1.8014700e-05, 5.4310156e-05, 8.3490449e-05,\n",
       "         6.9416310e-05, 4.0852061e-05, 7.4409523e-05, 5.8665413e-05,\n",
       "         8.8056753e-05, 3.6739839e-05]], dtype=float32)>,\n",
       " 90: <tf.Variable 'attention_block5_conv1/seeds:0' shape=(1, 90) dtype=float32, numpy=\n",
       " array([[ 3.0047067e-03,  8.8497195e-03,  2.7861327e-03, -0.0000000e+00,\n",
       "          2.2667272e-03,  9.1257738e-03,  8.5425097e-03, -0.0000000e+00,\n",
       "         -0.0000000e+00,  1.0737116e-03, -0.0000000e+00, -0.0000000e+00,\n",
       "          1.7465496e-03,  2.0011603e-03,  2.2104435e-04, -0.0000000e+00,\n",
       "          3.5895857e-03, -0.0000000e+00,  3.1625547e-03,  4.5759964e-05,\n",
       "         -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,  7.1041955e-04,\n",
       "          6.8165655e-03,  8.6650788e-04,  4.7474788e-03, -0.0000000e+00,\n",
       "          2.3653540e-03,  8.3993990e-03,  2.3896946e-03, -0.0000000e+00,\n",
       "          1.7536564e-03, -0.0000000e+00,  3.1115076e-05,  4.9913815e-06,\n",
       "         -0.0000000e+00,  1.1413224e-03, -0.0000000e+00,  2.1918816e-03,\n",
       "         -0.0000000e+00,  2.4542636e-03,  4.8233982e-04,  4.2422437e-03,\n",
       "          8.0028089e-04,  1.2276368e-02,  6.7590305e-04,  8.2351279e-04,\n",
       "          2.0127252e-04,  4.1757000e-04,  2.0115993e-03,  3.1375172e-04,\n",
       "         -0.0000000e+00,  1.8828416e-03,  1.9869790e-03,  2.1804869e-03,\n",
       "          3.3881885e-04, -0.0000000e+00,  4.7236285e-03,  2.9961872e-04,\n",
       "          4.1640425e-05, -0.0000000e+00,  2.9887194e-03,  1.1729349e-02,\n",
       "          2.4375520e-03,  5.5231038e-03, -0.0000000e+00,  1.8986365e-03,\n",
       "         -0.0000000e+00,  6.1876024e-04,  1.3914527e-03,  4.8796155e-05,\n",
       "         -0.0000000e+00,  2.1763885e-04,  9.7453976e-03,  1.4352928e-04,\n",
       "          7.8910589e-03,  2.3693722e-03,  4.2830380e-03,  5.8674620e-04,\n",
       "          3.4465200e-05,  8.1882789e-04,  1.5933838e-04,  1.0053756e-03,\n",
       "          6.6136307e-04,  5.1985881e-03,  5.9238989e-03,  3.3578314e-03,\n",
       "          3.5535751e-03,  1.4244613e-03]], dtype=float32)>,\n",
       " 256: <tf.Variable 'attention_block5_conv1/seeds:0' shape=(1, 256) dtype=float32, numpy=\n",
       " array([[-0.0000000e+00,  2.2926666e-03,  3.5693289e-03,  3.7370509e-04,\n",
       "         -0.0000000e+00,  1.4997364e-04, -0.0000000e+00,  1.8256077e-03,\n",
       "          9.5109438e-04,  3.5901906e-04,  1.4879940e-04, -0.0000000e+00,\n",
       "         -0.0000000e+00,  1.2862950e-03,  2.4530358e-04, -0.0000000e+00,\n",
       "          9.3115508e-05, -0.0000000e+00, -0.0000000e+00,  4.5214107e-04,\n",
       "         -0.0000000e+00,  4.4824756e-03, -0.0000000e+00,  2.5911964e-04,\n",
       "          2.7389606e-03, -0.0000000e+00,  4.0608994e-03,  3.8209146e-06,\n",
       "          4.3754047e-03,  1.0100247e-04,  6.7741305e-05,  1.8733495e-04,\n",
       "          4.0198807e-03, -0.0000000e+00,  5.8231381e-06,  4.9315053e-03,\n",
       "         -0.0000000e+00,  2.1283957e-04,  5.0299359e-04, -0.0000000e+00,\n",
       "          2.5312897e-06, -0.0000000e+00,  3.4941698e-03,  1.1171126e-03,\n",
       "         -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,  2.8322199e-03,\n",
       "         -0.0000000e+00,  3.0287667e-04, -0.0000000e+00,  9.1294962e-04,\n",
       "          3.9153723e-03, -0.0000000e+00,  2.0436564e-05,  8.8492474e-03,\n",
       "         -0.0000000e+00,  1.0282352e-03, -0.0000000e+00,  4.6814684e-04,\n",
       "         -0.0000000e+00,  1.5421252e-04,  9.9857338e-04,  6.9050142e-04,\n",
       "          2.9974952e-03,  9.1811764e-04, -0.0000000e+00,  6.9114827e-03,\n",
       "          2.0744132e-03,  8.1096987e-06, -0.0000000e+00,  4.8788967e-05,\n",
       "         -0.0000000e+00,  6.5683053e-05,  2.6205075e-03, -0.0000000e+00,\n",
       "         -0.0000000e+00, -0.0000000e+00,  1.6630325e-03, -0.0000000e+00,\n",
       "          5.8570039e-04, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "         -0.0000000e+00,  2.8253591e-04,  7.8171783e-04, -0.0000000e+00,\n",
       "          2.3146640e-06, -0.0000000e+00,  5.0869491e-04, -0.0000000e+00,\n",
       "          3.3432075e-03, -0.0000000e+00,  2.9695861e-03, -0.0000000e+00,\n",
       "         -0.0000000e+00,  5.7839457e-04,  2.4629736e-04,  7.7054712e-05,\n",
       "          2.6253981e-03, -0.0000000e+00,  6.1671092e-04, -0.0000000e+00,\n",
       "         -0.0000000e+00,  6.2057720e-03,  9.6239055e-05,  1.5893013e-03,\n",
       "          1.1599973e-04,  6.8971858e-04,  1.9523549e-03,  1.8115959e-04,\n",
       "         -0.0000000e+00,  1.1700019e-03, -0.0000000e+00,  3.5588801e-04,\n",
       "         -0.0000000e+00,  3.1276301e-03,  4.2344630e-03, -0.0000000e+00,\n",
       "         -0.0000000e+00, -0.0000000e+00,  9.7797092e-05,  2.6793287e-03,\n",
       "          3.3541538e-03,  6.5172510e-04, -0.0000000e+00, -0.0000000e+00,\n",
       "          1.6524562e-03,  6.0519739e-04,  6.6196808e-05,  6.9129248e-03,\n",
       "          7.7200896e-04, -0.0000000e+00,  3.6495831e-04,  4.5703920e-05,\n",
       "          8.9581343e-05, -0.0000000e+00,  2.9248025e-04, -0.0000000e+00,\n",
       "         -0.0000000e+00,  9.3667826e-05,  1.6461392e-03,  6.0116653e-03,\n",
       "          5.4515153e-04,  1.0204055e-02, -0.0000000e+00, -0.0000000e+00,\n",
       "          1.0137709e-03,  2.9970653e-04, -0.0000000e+00, -0.0000000e+00,\n",
       "          5.5682063e-03,  1.3775179e-02, -0.0000000e+00,  7.1328790e-03,\n",
       "         -0.0000000e+00,  1.1664407e-03,  9.6902666e-05,  7.9861609e-04,\n",
       "         -0.0000000e+00,  1.6751490e-04,  2.5561170e-03, -0.0000000e+00,\n",
       "         -0.0000000e+00,  3.2107162e-03,  3.2379210e-04,  2.8733843e-06,\n",
       "         -0.0000000e+00,  2.4242664e-04,  1.2730163e-02,  2.7868658e-04,\n",
       "         -0.0000000e+00,  1.1797514e-02,  1.3863330e-04,  2.2355332e-03,\n",
       "          2.3787034e-05,  8.9004112e-05, -0.0000000e+00, -0.0000000e+00,\n",
       "          4.9945512e-03,  8.8424305e-05,  4.2033981e-04,  1.1200122e-04,\n",
       "         -0.0000000e+00,  3.0731901e-03,  3.5687799e-03,  4.0768487e-03,\n",
       "          6.1045037e-05,  4.3032276e-03,  1.1793392e-03, -0.0000000e+00,\n",
       "         -0.0000000e+00,  5.0184056e-03,  1.9348277e-03,  2.3349817e-03,\n",
       "          3.8769536e-04,  5.4187013e-04, -0.0000000e+00, -0.0000000e+00,\n",
       "         -0.0000000e+00,  3.8373686e-04, -0.0000000e+00,  7.8396797e-03,\n",
       "         -0.0000000e+00,  1.1204545e-03, -0.0000000e+00, -0.0000000e+00,\n",
       "          2.8633133e-03, -0.0000000e+00,  4.9663428e-04,  8.0418678e-05,\n",
       "         -0.0000000e+00, -0.0000000e+00,  2.0847892e-04, -0.0000000e+00,\n",
       "          3.5905332e-04,  4.8741527e-05,  3.5608511e-03,  7.4490905e-03,\n",
       "         -0.0000000e+00,  7.7704043e-04, -0.0000000e+00,  6.3110352e-04,\n",
       "          1.1052230e-03,  5.5278459e-04,  1.7169417e-03,  8.5024658e-04,\n",
       "         -0.0000000e+00,  5.8647595e-07,  1.4865721e-03, -0.0000000e+00,\n",
       "          1.4202975e-03,  2.2022421e-03, -0.0000000e+00,  1.2992816e-03,\n",
       "         -0.0000000e+00,  8.5780176e-04,  3.3050936e-03,  1.9965423e-03,\n",
       "         -0.0000000e+00,  3.9202912e-04,  8.4669347e-04,  2.5386922e-04,\n",
       "         -0.0000000e+00,  1.4424344e-03,  8.6556319e-03,  3.0611169e-05,\n",
       "          6.7886233e-04, -0.0000000e+00,  3.9003282e-03, -0.0000000e+00,\n",
       "          4.4462015e-04, -0.0000000e+00,  7.0164133e-05, -0.0000000e+00]],\n",
       "       dtype=float32)>}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable subsampling equal to standard size\n",
    "train_set.set_subsampling(size=1170*2, force_class_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 322s 19s/step - loss: 0.6138 - accuracy: 0.8236 - val_loss: 0.7642 - val_accuracy: 0.7892\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 322s 19s/step - loss: 0.6785 - accuracy: 0.8141 - val_loss: 0.7639 - val_accuracy: 0.7900\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 324s 19s/step - loss: 0.7259 - accuracy: 0.8039 - val_loss: 0.7605 - val_accuracy: 0.7904\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 319s 19s/step - loss: 0.7055 - accuracy: 0.8029 - val_loss: 0.7634 - val_accuracy: 0.7908\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 322s 19s/step - loss: 0.6921 - accuracy: 0.7926 - val_loss: 0.7591 - val_accuracy: 0.7918\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 319s 19s/step - loss: 0.7015 - accuracy: 0.7900 - val_loss: 0.7649 - val_accuracy: 0.7907\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 320s 19s/step - loss: 0.6689 - accuracy: 0.8141 - val_loss: 0.7626 - val_accuracy: 0.7896\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 318s 19s/step - loss: 0.6922 - accuracy: 0.8066 - val_loss: 0.7525 - val_accuracy: 0.7938\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 320s 19s/step - loss: 0.6491 - accuracy: 0.8154 - val_loss: 0.7575 - val_accuracy: 0.7920\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 317s 19s/step - loss: 0.8126 - accuracy: 0.7844 - val_loss: 0.7625 - val_accuracy: 0.7903\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 321s 19s/step - loss: 0.6608 - accuracy: 0.8262 - val_loss: 0.7646 - val_accuracy: 0.7900\n"
     ]
    }
   ],
   "source": [
    "# Train and use CSV logger to store logs\n",
    "if not os.path.exists(log_path):\n",
    "    with open(log_path, \"w\") as my_empty_csv: pass\n",
    "\n",
    "csv_logger = CSVLogger(log_path, separator=',', append=False)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "train_history = train_model(model=model, train_set=train_set, val_set=val_set, epochs=epochs, batch_size=batch_size, callbacks=[csv_logger, early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took 16, 16, 14, 18 for convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9, 10, 10, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/baselines2/baseline90')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f17484d16d0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f'models/baselines/baseline256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting on test-set...\n",
      "48238/48238 [==============================] - 239s 5ms/step\n",
      "Computing accuracy...\n",
      "\n",
      "-----------------------------------------\n",
      "Model Accuracy on test-set: 0.6979766988681123\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('splash2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "febfae6c9c9e1571e6e03dfd739a8f6fb010085a8ae682416bd437b2f090be32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
