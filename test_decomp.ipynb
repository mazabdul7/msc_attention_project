{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Must be set before importing TF to supress messages\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils.configs import config\n",
    "from typing import List\n",
    "import pymf\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_VGG_model(img_height: int, img_width: int, lr: int, loss: tf.keras.losses.Loss, metrics: List[str], trainable: True) -> tf.keras.Model:\n",
    "    \"\"\" Loads VGG-16 model.\n",
    "\n",
    "    Args:\n",
    "        img_height (int): Image height.\n",
    "        img_width (int): Image width.\n",
    "        lr (int): Learning rate.\n",
    "        loss (tf.keras.losses.Loss): Model loss.\n",
    "        metrics (List[str]): Training metrics.\n",
    "        trainable (True): Set if model weights should be kept frozen or not.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: TensorFlow VGG-16 model.\n",
    "    \"\"\"\n",
    "    model = tf.keras.applications.vgg16.VGG16(input_shape=(img_height, img_width, 3))\n",
    "    model.trainable = trainable\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr, epsilon=0.1),\n",
    "                loss=loss,\n",
    "                metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_pcs(data, n_comp):\n",
    "    svd = np.linalg.svd(data, full_matrices=True) # Take full matrix - P is already ready\n",
    "    U = svd[0]\n",
    "    S = np.vstack([np.diag(svd[1]), np.zeros((svd[0].shape[0]-min(data.shape), svd[1].shape[0]))]) # Reconstruct true S matrix\n",
    "    VT = svd[2]\n",
    "\n",
    "    # Extract the top n_comp principal components\n",
    "    U_f = U[:, :n_comp]\n",
    "    S_f = S[:n_comp, :n_comp]\n",
    "    V_f = VT[:n_comp, :] # rows of VT contain the principle axes\n",
    "\n",
    "    return U_f, S_f, V_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_VGG_model(img_height=224, img_width=224, lr=0.001, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'], trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = model.get_layer('block4_conv2').kernel\n",
    "flat_kernel = tf.reshape(kernel, [-1, kernel.shape[-1]]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_fk = ((flat_kernel - np.mean(flat_kernel, axis=0)) / np.std(flat_kernel, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = pymf.SNMF(flat_kernel.T, num_bases=90)\n",
    "nmf.factorize(niter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (4608, 512)\n",
      "W Shape: (512, 90), H shape: (90, 4608)\n",
      "[[0.73764775 0.7528971  0.59190911 ... 0.958576   0.6760751  0.76307495]\n",
      " [0.30181689 0.25709903 0.84324327 ... 0.24214831 0.00519485 0.01294836]\n",
      " [0.1366661  0.70271647 0.26033878 ... 0.57364907 0.47377842 0.05059574]\n",
      " ...\n",
      " [0.76121811 0.76182188 0.59391574 ... 0.43254617 0.35416131 0.64657014]\n",
      " [0.73507097 0.85946173 0.01798513 ... 0.30071964 0.63542806 0.7460896 ]\n",
      " [0.60270452 0.86541689 0.59534312 ... 0.74906893 0.3799919  0.92967351]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Original Data Shape: {flat_kernel.shape}')\n",
    "print(f'W Shape: {nmf.W.shape}, H shape: {nmf.H.shape}')\n",
    "print(nmf.H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,v = retrieve_pcs(flat_kernel.T, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 90)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(90)\n",
    "reduced = pca.fit_transform(flat_kernel)\n",
    "X_re_orig = pca.inverse_transform(reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNMF: Residual Sum Square Error: 55.002846404742044\n",
      "Manual SVD PCA: Residual Sum Square Error: 53.68510261014783\n",
      "Sklearn PCA: Residual Sum Square Error: 53.781124114990234\n"
     ]
    }
   ],
   "source": [
    "rss_nmf = np.sum(np.square(flat_kernel - nmf.W@nmf.H))\n",
    "print(f'SNMF: Residual Sum Square Error: {rss_nmf}')\n",
    "\n",
    "rss_svd = np.sum(np.square(flat_kernel - u@s@v))\n",
    "print(f'Manual SVD PCA: Residual Sum Square Error: {rss_svd}')\n",
    "\n",
    "rss_pca = np.sum(np.square(flat_kernel - X_re_orig.T))\n",
    "print(f'Sklearn PCA: Residual Sum Square Error: {rss_pca}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNMF: Explained Variance: 0.5767240317161563\n",
      "Manual SVD PCA: Explained Variance: 0.5952852970918956\n",
      "Sklearn PCA: Explained Variance: 0.5943224234506488\n"
     ]
    }
   ],
   "source": [
    "snmf_var = sklearn.metrics.explained_variance_score(flat_kernel, nmf.W@nmf.H)\n",
    "print(f'SNMF: Explained Variance: {snmf_var}')\n",
    "\n",
    "svd_var = sklearn.metrics.explained_variance_score(flat_kernel, u@s@v)\n",
    "print(f'Manual SVD PCA: Explained Variance: {svd_var}')\n",
    "\n",
    "pca_var = sklearn.metrics.explained_variance_score(flat_kernel, X_re_orig.T)\n",
    "print(f'Sklearn PCA: Explained Variance: {pca_var}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('splash2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "febfae6c9c9e1571e6e03dfd739a8f6fb010085a8ae682416bd437b2f090be32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
