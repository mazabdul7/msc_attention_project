{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import sample\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Must be set before importing TF to supress messages\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import numpy as np\n",
    "from utils.loader import DataLoader\n",
    "from utils.tools import test_model\n",
    "from utils.data_sampler import CustomDataGenerator, CustomIterator\n",
    "from utils.configs import config\n",
    "from typing import List\n",
    "\n",
    "def load_VGG_model(img_height: int, img_width: int, lr: int, loss: tf.keras.losses.Loss, metrics: List[str], trainable: True) -> tf.keras.Model:\n",
    "    \"\"\" Loads VGG-16 model.\n",
    "\n",
    "    Args:\n",
    "        img_height (int): Image height.\n",
    "        img_width (int): Image width.\n",
    "        lr (int): Learning rate.\n",
    "        loss (tf.keras.losses.Loss): Model loss.\n",
    "        metrics (List[str]): Training metrics.\n",
    "        trainable (True): Set if model weights should be kept frozen or not.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: TensorFlow VGG-16 model.\n",
    "    \"\"\"\n",
    "    model = tf.keras.applications.vgg16.VGG16(input_shape=(img_height, img_width, 3))\n",
    "    model.trainable = trainable\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr, epsilon=0.1),\n",
    "                loss=loss,\n",
    "                metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model: tf.keras.Model, train_set: CustomIterator, val_set: CustomIterator, epochs: int, batch_size: int, callbacks=None):\n",
    "    \"\"\" Train the model. \n",
    "\n",
    "    Args:\n",
    "        train_set (CustomIterator): Training data.\n",
    "        val_set (CustomIterator): Validation data.\n",
    "        epochs (int): Number of epochs to train for.\n",
    "        callbacks (_type_, optional): Callbacks for loggers. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        history: Model training history information.\n",
    "    \"\"\"\n",
    "    history = model.fit(train_set, validation_data=val_set, epochs=epochs, steps_per_epoch=train_set.n//batch_size, validation_steps=val_set.n//batch_size, verbose=1, callbacks=callbacks)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test set...\n",
      "Found 48238 images belonging to 1000 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set configs\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "lr = 3e-5\n",
    "log_path = os.path.join(config['logs_path'], 'vgg_training_new.csv')\n",
    "\n",
    "# Set augmentation and pre-processing\n",
    "train_datagen = CustomDataGenerator(\n",
    "                horizontal_flip=True,\n",
    "                validation_split=0.1,\n",
    "                preprocessing_function=tf.keras.applications.vgg16.preprocess_input, dtype=tf.float32)\n",
    "test_datagen = CustomDataGenerator(\n",
    "                preprocessing_function=tf.keras.applications.vgg16.preprocess_input, dtype=tf.float32)\n",
    "\n",
    "# Load ImageNet dataset with the VGG augmentation\n",
    "loader = DataLoader(batch_size, (img_height, img_width))\n",
    "train_set = loader.load_train_set(aug_train=train_datagen, class_mode='categorical', shuffle=True)\n",
    "val_set = loader.load_val_set(aug_val=train_datagen, class_mode='categorical', shuffle=True)\n",
    "test_set = loader.load_test_set(aug_test=test_datagen, set_batch_size=False)\n",
    "\n",
    "train_set.set_subsampling(200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_VGG_model(img_height=img_height, img_width=img_width, lr=lr, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'], trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 3759s 1s/step - loss: 0.7629 - accuracy: 0.7923 - val_loss: 0.7823 - val_accuracy: 0.7852\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 3784s 1s/step - loss: 0.7439 - accuracy: 0.7965 - val_loss: 0.7801 - val_accuracy: 0.7854\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 3770s 1s/step - loss: 0.7346 - accuracy: 0.7980 - val_loss: 0.7691 - val_accuracy: 0.7874\n",
      "Epoch 4/5\n",
      " 717/3125 [=====>........................] - ETA: 29:51 - loss: 0.7279 - accuracy: 0.8011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mazin/.conda/envs/splash2/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:793: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 3738s 1s/step - loss: 0.7238 - accuracy: 0.8005 - val_loss: 0.7622 - val_accuracy: 0.7897\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 3742s 1s/step - loss: 0.7039 - accuracy: 0.8058 - val_loss: 0.7595 - val_accuracy: 0.7894\n"
     ]
    }
   ],
   "source": [
    "# Train and use CSV logger to store logs\n",
    "if not os.path.exists(os.path.join(config['logs_path'], 'vgg_training_neww.csv')):\n",
    "    with open(os.path.join(config['logs_path'], 'vgg_training_neww.csv'), \"w\") as my_empty_csv: pass\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(config['logs_path'], 'vgg_training_neww.csv'), separator=',', append=False)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "train_history = train_model(model=model, train_set=train_set, val_set=val_set, epochs=5, batch_size=batch_size, callbacks=[csv_logger, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('vgg_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting on test-set...\n",
      "48238/48238 [==============================] - 480s 10ms/step\n",
      "Computing accuracy...\n",
      "\n",
      "-----------------------------------------\n",
      "Model Accuracy on test-set: 0.6941622787014387\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vgg_trained')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('splash2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "febfae6c9c9e1571e6e03dfd739a8f6fb010085a8ae682416bd437b2f090be32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
